#!/usr/bin/env python3
"""
Python version of mkslurm_alt by Andrew Coward using HetJobs.
This version
"""
import argparse
import logging
import os
import sys
from textwrap import dedent


def main(args):
    """Create slurm scripts

    Args:
        args: Parsed arguments.
    """

    # Verbosity
    if args.v:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    cmd = f"{parser.prog} " + " ".join(
        [
            f"{'-' if len(arg)==1 else '--'}{arg.replace('_', '-')} {val}"
            for arg, val in vars(args).items()
        ]
    )
    logging.info("Running %s", cmd)

    # Check
    if args.g == 1 or args.g < 0:
        logging.critical("-g must be 0 or greater than 1.")
        sys.exit()

    # Find placements for each node
    nodes_mapper = _mkslurm_alt(args)

    # Group identical nodes: HetJob setup
    hetjob_mapper = _group_identical_nodes(nodes_mapper)

    # Print table
    _print_table(hetjob_mapper, args.N)

    # Build slurm script

    # SBATCH settings
    string = f"""\
    #!/bin/bash
    #SBATCH --job-name={args.j}
    #SBATCH --time={args.t}
    #SBATCH --account={args.a}
    #SBATCH --partition={args.p}
    #SBATCH --qos={args.q}
    #SBATCH --nodes={sum(val['nnodes'] for val in hetjob_mapper.values())}
    #SBATCH --ntasks-per-core=1
    """
    slurm = dedent(string)

    # Environment
    string = f"""
    # Created by: {cmd}
    source ../../code/archer2-files/ucx_env
    module list
    export OMP_NUM_THREADS=1
    """
    slurm += dedent(string)

    string = "#\n"
    for i, wdir in enumerate(args.D):
        string += f'cat > "$SLURM_SUBMIT_DIR"/wrapper_run_ens{i} << EOFB\n'
        string += "#!/bin/ksh\n#\n"
        string += f"# run ensemble: {i}\n#\n"
        string += f"cd {wdir}\n"
        string += f"./nemo\n"
        string += f"##\nEOFB\n"
        string += f'chmod u+x "$SLURM_SUBMIT_DIR"/wrapper_run_ens{i}\n'

    slurm += dedent(string)

    # string = "#\n"
    # for i, wdir in enumerate(args.D):
    #     string += f'cat > "$SLURM_SUBMIT_DIR"/wrapper_run_xios_ens{i} << EOFB\n'
    #     string += "#!/bin/ksh\n#\n"
    #     string += f"# run xios: {i}\n#\n"
    #     string += f"cd {wdir}\n"
    #     string += f"./xios_server.exe\n"
    #     string += f"##\nEOFB\n"
    #     string += f'chmod u+x "$SLURM_SUBMIT_DIR"/wrapper_run_xios_ens{i}\n'

    # slurm += dedent(string)

    slurm += "\n\n"

    string = 'cat > "$SLURM_SUBMIT_DIR"/myscript_wrapper.sh << EOFB\n'
    string += "#!/bin/ksh\n#\n"
    string += "set -A map ./xios_server.exe "
    # string += "set -A map "
    # string += " ".join([f"./wrapper_run_xios_ens{i}" for i, _ in enumerate(args.D)])
    # string += " "
    string += " ".join([f"./wrapper_run_ens{i}" for i, _ in enumerate(args.D)])
    string += "\n"
    string += "exec_map=( "
    string += " ".join(
        [
            str(ex + args.D.index(wd)) if ex != 0 else str(ex)
            # str(ex + args.D.index(wd) + len(args.D)-1) if ex != 0 else str(args.D.index(wd))
            for values in hetjob_mapper.values()
            for i in range(values["nnodes"])
            for ex, wd in zip(values["ex"], values["wd"])
        ]
    )
    string += " )\n"
    string += "exec \\${map[\\${exec_map[\\$SLURM_PROCID]}]}\n"
    string += "EOFB\n"
    string += f'chmod u+x "$SLURM_SUBMIT_DIR"/myscript_wrapper.sh\n'

    slurm += dedent(string)

    slurm += "\n\n"
    # Srun
    strings = []
    for het_group, values in hetjob_mapper.items():
        cores = [core for core in values["pl"]]
        if not cores:
            continue

        het_group_string = (
            f"--het-group={het_group} " if len(hetjob_mapper) > 1 else ""
        )
        strings += [
            het_group_string
            + f" --oversubscribe --nodes={values['nnodes']}"
            + f" --ntasks={len(cores)*values['nnodes']}"
            + f" --ntasks-per-node={len(cores)}"
            + " --cpu-bind=v,mask_cpu:"
            + ",".join([hex(2 ** core) for core in cores])
            + f' "$SLURM_SUBMIT_DIR"/myscript_wrapper.sh'
        ]
    string = "srun --mem-bind=local \\\n" + " \\\n: ".join(strings)
    slurm += "\n".join(
        [string + " &", 'cd "$SLURM_SUBMIT_DIR" || exit\n']
    )

    tail = f"""
    wait

    # Print stats
    sacct -j "$SLURM_JOB_ID" --units=G --format=JobID,JobName,NNodes,Elapsed,AveRSS,MaxRSS,MaxRSSNode,MaxRSSTask

    # Exit
    ERROR=$(grep "E R R O R" {" ".join([os.path.join(path, "*ocean.output*") for path in args.D])} | wc -l)
    if [ "$ERROR" -ne 0 ]; then
        echo "E R R O R"
        grep -c "E R R O R" {" ".join([os.path.join(path, "*ocean.output*") for path in args.D])}
    fi
    exit "$ERROR"
    """
    slurm += dedent(tail)

    print(slurm)


def _mkslurm_alt(args):
    """
    Python version of mkslurm_alt

    Args:
        args: Parsed arguments.

    Returns:
        Dictionary mapping nodes to their ex, pl
    """

    # Start loop
    nservers_left = args.S * len(args.D)
    nclients_left = args.C * len(args.D)
    nodes_mapper = {}
    cpu, totnserv, prevclie, skipnext, node = (0 for _ in range(5))
    while nservers_left or nclients_left:
        # Reset node
        cpu = 0 if cpu == args.N else cpu
        totnserv = totnserv if cpu else 0
        prevclie = prevclie if cpu else 0
        skipnext = skipnext if cpu else 0
        node = node if cpu else len(nodes_mapper)
        nodes_mapper.setdefault(node, {key: [] for key in ("ex", "pl", "wd")})
        if skipnext:
            skipnext -= 1
            cpu += 1
            prevclie = 0
            continue
        if totnserv < args.m and nservers_left:
            nodes_mapper[node]["ex"] += [0]
            nodes_mapper[node]["pl"] += [cpu]
            if args.alternate_dirs:
                nodes_mapper[node]["wd"] += [args.D[nservers_left % len(args.D)]]
            else:
                nodes_mapper[node]["wd"] += [
                    args.D[::-1][(nservers_left - 1) // args.S]
                ]
            skipnext = args.s - 1
            nservers_left -= 1
            totnserv += 1
        elif nclients_left:
            nodes_mapper[node]["ex"] += [1]
            nodes_mapper[node]["pl"] += [cpu]
            if args.alternate_dirs:
                nodes_mapper[node]["wd"] += [args.D[nclients_left % len(args.D)]]
            else:
                nodes_mapper[node]["wd"] += [
                    args.D[::-1][(nclients_left - 1) // args.C]
                ]
            nclients_left -= 1
            prevclie += 1
            skipnext = prevclie == args.g - 1
        cpu += 1
    nodes_needed = len(nodes_mapper)
    reserved_cores = nodes_needed * args.N
    cores_used = sum(len(values["ex"]) for values in nodes_mapper.values())
    reserved_cores_needed = (
        args.S * args.s + args.C + (args.C // (args.g - 1) if args.g else 0)
    ) * len(args.D)
    logging.info("nodes needed= %s (%s)", nodes_needed, reserved_cores)
    logging.info("cores to be used= %s (%s)", cores_used, reserved_cores_needed)

    return nodes_mapper


def _group_identical_nodes(nodes_mapper):
    """
    Group identical nodes to HetJobs

    Args:
        nodes_mapper: Dictionary mapping nodes to their ex, pl, and wd

    Returns:
        Dictionary mapping het-groups to their ex, pl, wd, and nnodes
    """
    # Group nodes for HetJob
    hetjob_mapper = {}
    het_group = 0
    # Loop over nodes
    for node_values in nodes_mapper.values():
        hetjob_found = False
        # Loop over hetjobs already found
        for hetjob_values in hetjob_mapper.values():
            hetjob_found = all(
                hetjob_values[key] == node_values[key] for key in ["ex", "pl", "wd"]
            )
            if hetjob_found:
                # Add to existing hetjob
                hetjob_values["nnodes"] += 1
                break
        # Create new hetjob
        if not hetjob_found:
            hetjob_mapper[het_group] = node_values
            hetjob_mapper[het_group]["nnodes"] = 1
            het_group += 1

    return dict(sorted(hetjob_mapper.items()))


def _print_table(hetjob_mapper, ncores_per_node):
    """
    Print a human readable table of the setup.

    Args:
        hetjob_mapper: Dictionary mapping het-groups to their ex, pl, and nnodes
        ncores_per_node: Number of cores per node
    """
    # Loop to create table
    groups, nodes, cores, tasks, wdirs = ([] for i in range(5))
    for group, values in enumerate(hetjob_mapper.values()):
        nnodes = values["nnodes"]
        # Build table
        for core in range(ncores_per_node):
            if core in values["pl"]:
                task = "c" if values["ex"][values["pl"].index(core)] else "s"
                wdir = values["wd"][values["pl"].index(core)]
            else:
                task = wdir = "-"
            groups += [group]
            nodes += [nnodes]
            cores += [core]
            tasks += [task]
            wdirs += [wdir]

    # Print table
    header = ("group", "nodes", "core", "task", "directory")
    logging.debug("{:>5} {:>5} {:>5} {:>5} {}".format(*header))
    for line in zip(groups, nodes, cores, tasks, wdirs):
        logging.debug("{:>5} {:>5} {:>5} {:>5} {}".format(*line))


if __name__ == "__main__":
    # Parse arguments
    parser = argparse.ArgumentParser(
        prog="mkslurm_hetjob_ensemble",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description=" ".join(
            [
                "Python version of mkslurm_alt by Andrew Coward using HetJob.",
                "Server placement and spacing remains",
                "as mkslurm but clients are always tightly packed with a gap left",
                'every "NC_GAP" cores where NC_GAP can be given by the -g argument.',
                "values of 4, 8 or 16 are recommended.",
                "This version allows to submit ensemble runs (e.g., -D dir1 dir2).",
            ]
        ),
        prefix_chars="-",
    )
    parser.add_argument("-S", help="number of servers", type=int, default=4)
    parser.add_argument("-s", help="server spacing", type=int, default=8)
    parser.add_argument(
        "-m", help="max number of servers per node", type=int, default=2
    )
    parser.add_argument("-C", help="number of clients", type=int, default=28)
    parser.add_argument("-g", help="client gap interval", type=int, default=4)
    parser.add_argument(
        "-D", help="ensemble directories", type=str, nargs="+", default="."
    )
    parser.add_argument(
        "--alternate-dirs",
        help="alternate ensemble directories to minimize the number of hetjobs",
        action="store_true",
    )
    parser.add_argument("-N", help="number of cores per node", type=int, default=128)
    parser.add_argument("-t", help="time limit", type=str, default="00:10:00")
    parser.add_argument("-a", help="account", type=str, default="n01")
    parser.add_argument("-j", help="job name", type=str, default="nemo_test")
    parser.add_argument("-p", help="partition", type=str, default="standard")
    parser.add_argument("-q", help="quality of service", type=str, default="standard")
    parser.add_argument("-v", help="show human readable hetjobs", action="store_true")
    parser.add_argument("--gnu", help="use GNU compiler", action="store_true")
    # Let's go!
    main(parser.parse_args())

